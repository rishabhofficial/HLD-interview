# Ad Click Aggregator - Quick Cheatsheet

> â±ï¸ **5-minute revision before interview**

---

## ğŸ“‹ Requirements Summary

### Functional Requirements
| # | Requirement |
|---|-------------|
| 1 | Users click ads â†’ redirected to advertiser site |
| 2 | Advertisers query click metrics (1-min granularity) |

### Non-Functional Requirements
| # | Requirement | Target |
|---|-------------|--------|
| 1 | Throughput | 10k clicks/second |
| 2 | Query Latency | Sub-second |
| 3 | Data Accuracy | Zero data loss |
| 4 | Freshness | Near real-time |
| 5 | Idempotency | No duplicate counts |

---

## ğŸ—ï¸ High-Level Architecture

```mermaid
flowchart TB
    subgraph Users
        U[Users]
    end

    subgraph Ingestion
        CP[Click Processor]
    end

    subgraph Stream[Stream Layer]
        Kafka[Kafka]
        Flink[Flink]
    end

    subgraph Storage
        OLAP[(OLAP DB)]
        S3[(S3 Lake)]
    end

    subgraph Batch
        Spark[Spark]
    end

    subgraph Query
        QS[Query Service]
    end

    U -->|Click| CP
    CP -->|302 Redirect| U
    CP --> Kafka
    Kafka --> Flink --> OLAP
    Kafka --> S3 --> Spark --> OLAP
    QS --> OLAP
```

---

## ğŸ” Deep Dives

### 1. Redirect Handling

| Approach | Description | Verdict |
|----------|-------------|---------|
| âŒ **Client Redirect** | JS pixel fires to advertiser | Bad - Ad blockers, unreliable |
| âœ… **Server Redirect** | Click â†’ Server â†’ 302 | Good - Full control, accurate |

```
âœ… GOOD: User clicks â†’ /click endpoint â†’ Track â†’ 302 Redirect
âŒ BAD:  User clicks â†’ Direct to advertiser + Fire pixel (blocked!)
```

### 2. Click Processing

| Approach | Description | Verdict |
|----------|-------------|---------|
| âŒ **Sync DB Write** | Write directly to OLAP | Bad - Slow, not scalable |
| âš ï¸ **Batch Processing** | Accumulate â†’ Periodic job | OK - Minutes latency |
| âœ… **Stream Processing** | Kafka â†’ Flink â†’ OLAP | Good - Seconds latency |

```
âœ… GOOD: Click â†’ Kafka â†’ Flink (1-min windows) â†’ OLAP â†’ Query in seconds
âŒ BAD:  Click â†’ Direct OLAP insert â†’ Slow queries, high write load
```

### 3. Fault Tolerance & Data Accuracy

| Approach | Description | Verdict |
|----------|-------------|---------|
| âŒ **Stream Only** | Trust Flink completely | Bad - Processing errors happen |
| âœ… **Stream + Reconciliation** | Real-time + Daily batch compare | Good - Catches all errors |

```
âœ… GOOD:
   Real-time: Kafka â†’ Flink â†’ OLAP (fast)
   Batch:     S3 â†’ Spark â†’ Compare with OLAP â†’ Fix discrepancies

âŒ BAD: Only stream processing, never verify accuracy
```

**Checkpointing Decision:**
```
1-minute windows â†’ Don't need checkpointing (just replay from Kafka)
1-hour+ windows â†’ Need checkpointing (too much to recompute)

ğŸ’¡ Interview Insight: Show critical thinking, not just textbook answers!
```

### 4. Hot Shards (Viral Ads)

| Approach | Description | Verdict |
|----------|-------------|---------|
| âŒ **Ignore** | Let shard overload | Bad - Data loss, latency |
| âœ… **Salted Keys** | ad_id:random(0-N) | Good - Spreads load |

```
âœ… GOOD: nike_123 â†’ nike_123:0, nike_123:1, ... nike_123:9 â†’ 10 partitions
âŒ BAD:  nike_123 â†’ All 8000 clicks/s to 1 partition â†’ Overload!
```

### 5. Idempotency (Duplicate Prevention)

| Approach | Description | Verdict |
|----------|-------------|---------|
| âŒ **DB Constraint** | Reject at write time | Bad - Already processed |
| âœ… **Flink Dedup** | State with TTL | Good - Real-time dedup |

```
âœ… GOOD:
   click_id = hash(ad_id + user_id + timestamp_minute)
   Flink keeps 5-min state â†’ Drops duplicates

âŒ BAD: Count all clicks, check for duplicates later
```

### 6. Low Latency Queries

| Approach | Description | Verdict |
|----------|-------------|---------|
| âŒ **Query Raw Minutes** | Aggregate at query time | Bad - Slow for large ranges |
| âœ… **Pre-aggregation** | Roll up to hour/day/week | Good - O(1) for any range |

```
âœ… GOOD:
   1-min â†’ hourly rollup â†’ daily rollup â†’ monthly rollup
   Query monthly? Read 12 rows, not 525,600!

âŒ BAD: Query a year of 1-minute data = 525,600 rows to aggregate
```

---

## ğŸ“Š Key Numbers

| Metric | Value |
|--------|-------|
| Peak clicks/second | 10,000 |
| Daily clicks | 100 million |
| Active ads | 10 million |
| Kafka shard limit | 1 MB/s or 1000 rec/s |
| Event size | ~200 bytes |
| Daily raw storage | ~20 GB |
| Kafka shards needed | 10-15 |

---

## ğŸ’¬ Interview Phrases

1. *"Kafka + Flink for real-time aggregation with sub-second latency"*
2. *"Partition by ad_id ensures all events for an ad go to same processor"*
3. *"Daily reconciliation from S3 catches any real-time processing errors"*
4. *"Salt partition keys for hot ads to spread load"*
5. *"Pre-aggregated rollups enable sub-second queries for any time range"*

---

## âš ï¸ Pitfalls to Avoid

1. âŒ Writing directly to OLAP without stream
2. âŒ Ignoring hot shard problem
3. âŒ No reconciliation process
4. âŒ Client-side redirect only
5. âŒ Over-engineering checkpointing for small windows

---

## ğŸ—ï¸ Technology Stack

| Component | Technology |
|-----------|------------|
| Stream | Kafka / Kinesis |
| Processor | Apache Flink |
| OLAP | ClickHouse / Druid |
| Data Lake | S3 |
| Batch | Spark |
